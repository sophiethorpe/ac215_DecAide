{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68pN4BG7BjAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4e13cf-6549-4d42-989e-3560330da131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.cloud import storage\n",
        "from urllib.parse import quote\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEREmC-O3ART",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212e43d8-edf6-459b-adff-5299b36d8032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "!gcloud config set project \"ac215-decaide\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SyhFdHeH3FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15188df4-aae2-4f1d-9e73-49b97c4af99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are running on a Google Compute Engine virtual machine.\n",
            "The service credentials associated with this virtual machine\n",
            "will automatically be used by Application Default\n",
            "Credentials, so it is not necessary to use this command.\n",
            "\n",
            "If you decide to proceed anyway, your user credentials may be visible\n",
            "to others with access to this virtual machine. Are you sure you want\n",
            "to authenticate with your personal account?\n",
            "\n",
            "Do you want to continue (Y/n)?  Y\n",
            "\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=lCTjkteQU08Bn9iZesJytTv966p840&prompt=consent&token_usage=remote&access_type=offline&code_challenge=dJz_Kwv59d0O-qfCj72MK0kQ6-NTSrnNAaBiPBThzJI&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AVG7fiQeXOnSgfPHfTJZH43ECHA0Bqo7s4ZCoRL1tfe4ErrBcYj53pW8p1HW6Pzx7GvS2Q\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"ac215-decaide\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ23-luRE9ns"
      },
      "source": [
        "# Loading Data\n",
        "\n",
        "GCP bucket link: https://console.cloud.google.com/storage/browser/ac215-decaide;tab=objects?forceOnBucketsSortingFiltering=true&authuser=1&project=ac215-decaide&supportedpurview=project&prefix=&forceOnObjectsSortingFiltering=false\n",
        "\n",
        "It takes 6 minutes to run the cell that loads all data from the GCP bucket subfolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTRuI79kIZX4"
      },
      "outputs": [],
      "source": [
        "# Load the metadata CSV file\n",
        "metadata_file = '/content/drive/MyDrive/APCOMP 215/AC_215/data/clean_metadata.csv'\n",
        "metadata_df = pd.read_csv('clean_metadata.csv')\n",
        "\n",
        "# Initialize the GCS client and bucket\n",
        "client = storage.Client()\n",
        "bucket_name = 'ac215-decaide'\n",
        "bucket = client.bucket(bucket_name)\n",
        "folder_path = 'images/clean_data/'\n",
        "blobs = bucket.list_blobs(prefix=folder_path) # List all blobs in the specified folder\n",
        "\n",
        "# Lists to hold images and paths\n",
        "images = []\n",
        "image_paths = []\n",
        "\n",
        "# Function to load an image from GCP bucket\n",
        "def load_image_from_gcp(bucket, image_path):\n",
        "  img_blob = bucket.blob(image_path)\n",
        "\n",
        "  # Download the image bytes and decode them\n",
        "  img_bytes = img_blob.download_as_bytes()\n",
        "  img = tf.image.decode_image(img_bytes, channels=3)\n",
        "  img = tf.image.resize(img, (224, 224))\n",
        "  return img\n",
        "\n",
        "# Load all images from the specified folder in the bucket\n",
        "for blob in blobs:\n",
        "  img_path = blob.name  # Get the full blob name (path)\n",
        "\n",
        "  try:\n",
        "    img = load_image_from_gcp(bucket, img_path)\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    images.append(img_array)\n",
        "    image_paths.append(img_path)\n",
        "  except Exception as e:\n",
        "    print(f\"Error loading {img_path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KphcXrh3-dIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3058c0-a62e-4a78-8fab-c2d7ac399ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in cleaned/filtered metadata_df: 5554 \n",
            " Number of images that exist and were loaded from GCP: 5554\n"
          ]
        }
      ],
      "source": [
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Function to process images in smaller batches\n",
        "def process_images(image_batch):\n",
        "    images_tensor = tf.convert_to_tensor(image_batch, dtype=tf.float32)\n",
        "    # Normalize using the mean and std for ImageNet\n",
        "    mean = tf.constant([0.485, 0.456, 0.406])\n",
        "    std = tf.constant([0.229, 0.224, 0.225])\n",
        "    return (images_tensor - mean) / std\n",
        "\n",
        "# Load images in smaller batches and process\n",
        "processed_images = []\n",
        "for batch in range(0, len(images), batch_size):\n",
        "    image_batch = images[batch:batch + batch_size]\n",
        "    processed_images.append(process_images(image_batch))\n",
        "\n",
        "# Concatenate all processed images\n",
        "images = tf.concat(processed_images, axis=0)\n",
        "\n",
        "# Clean and filter metadata_df since there are duplicates\n",
        "image_paths = [path.replace('images/clean_data/', '') for path in image_paths]\n",
        "metadata_df = metadata_df.drop_duplicates(subset='filename', keep='first')\n",
        "metadata_df = metadata_df[metadata_df['filename'].isin(image_paths)]\n",
        "print(f\"Number of images in cleaned/filtered metadata_df: {metadata_df.shape[0]} \\n Number of images that exist and were loaded from GCP: {len(image_paths)}\")\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(metadata_df['label'].values)\n",
        "categorical_labels = tf.keras.utils.to_categorical(encoded_labels)\n",
        "\n",
        "# Create a TensorFlow Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, categorical_labels))\n",
        "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clodSVkqE0vh"
      },
      "source": [
        "# ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbjVSyoQEqwD",
        "outputId": "377b01e0-35ca-457e-f877-8ac5b51237d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.2089 - loss: 4.9285\n",
            "Epoch 2/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.2998 - loss: 3.2449\n",
            "Epoch 3/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.3441 - loss: 3.0046\n",
            "Epoch 4/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.3581 - loss: 2.7546\n",
            "Epoch 5/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.3963 - loss: 2.6222\n",
            "Epoch 6/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.4138 - loss: 2.3170\n",
            "Epoch 7/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.4529 - loss: 2.0873\n",
            "Epoch 8/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.4723 - loss: 2.0081\n",
            "Epoch 9/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.4915 - loss: 1.9221\n",
            "Epoch 10/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5259 - loss: 1.9560\n",
            "Epoch 11/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5293 - loss: 1.8183\n",
            "Epoch 12/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5790 - loss: 1.6416\n",
            "Epoch 13/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5973 - loss: 1.4840\n",
            "Epoch 14/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6582 - loss: 1.1642\n",
            "Epoch 15/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.6885 - loss: 1.0389\n",
            "Epoch 16/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7243 - loss: 0.9284\n",
            "Epoch 17/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7598 - loss: 0.8685\n",
            "Epoch 18/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7542 - loss: 0.9447\n",
            "Epoch 19/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7998 - loss: 0.7824\n",
            "Epoch 20/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7982 - loss: 0.7467\n",
            "Epoch 21/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8366 - loss: 0.5744\n",
            "Epoch 22/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8399 - loss: 0.6256\n",
            "Epoch 23/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8427 - loss: 0.7388\n",
            "Epoch 24/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8749 - loss: 0.4829\n",
            "Epoch 25/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8985 - loss: 0.3307\n",
            "Epoch 26/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9076 - loss: 0.3275\n",
            "Epoch 27/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8475 - loss: 0.8060\n",
            "Epoch 28/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8708 - loss: 0.5761\n",
            "Epoch 29/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8702 - loss: 0.5928\n",
            "Epoch 30/30\n",
            "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9062 - loss: 0.3864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d4e7449f910>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Load ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze all layers except the last 10 -> fine-tune the last 10 layers\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(dataset, epochs=30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}